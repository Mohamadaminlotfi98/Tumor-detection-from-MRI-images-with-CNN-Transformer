# Define the ratio of samples to be used for testing and evaluation
test_split = 0.2  # 20% of the data will be used for testing
eval_split = 0.05  # 5% of the training data will be used for evaluation

# Get the number of samples in the dataset
dataset_size = len(dataset)
indices = list(range(dataset_size))

# Shuffle the indices to ensure a random split
random_seed = 42  # You can change the seed for reproducibility
random.seed(random_seed)
random.shuffle(indices)

# Create data samplers for training, evaluation, and testing
split_test = int(test_split * dataset_size)
split_eval = int(eval_split * (dataset_size - split_test))

train_indices = indices[split_test + split_eval:]
eval_indices = indices[split_test:split_test + split_eval]
test_indices = indices[:split_test]

train_sampler = SubsetRandomSampler(train_indices)
eval_sampler = SubsetRandomSampler(eval_indices)
test_sampler = SubsetRandomSampler(test_indices)

# Create data loaders for training, evaluation, and testing
batch_size = 32
train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)
eval_loader = DataLoader(dataset, batch_size=batch_size, sampler=eval_sampler)
test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)
